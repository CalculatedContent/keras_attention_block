{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections.abc import Callable,Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import merge\n",
    "from keras.layers.core import *\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = 32\n",
    "TIME_STEPS = 20\n",
    "SINGLE_ATTENTION_VECTOR = False\n",
    "APPLY_ATTENTION_BEFORE_LSTM = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention2DLayer(Layer):\n",
    "    \"\"\"加性相似度,最经典的注意力相似度机制,如果是在self attention中\\\n",
    "则该层有一个dim为Key_time_step的向量和一个(Key_dim,Key_time_step)的矩阵作为用于训练的参数\n",
    "\n",
    "    .. math::  Similarity(Key) = v \\cdot tanh(W_k\\cdot Key)\n",
    "\n",
    "\n",
    "如果不是在self attention中,则该层有一个dim为Key_time_step的向量和两个(Key_dim,Key_time_step)\\\n",
    "的矩阵作为用于训练的参数\n",
    "\n",
    "    .. math::  Similarity(Key) = v \\cdot tanh(W_k\\cdot Key+W_q\\cdot Query)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, similarity=\"additive\",*,\n",
    "                 kernel_size = None,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 wk_kernel_initializer='glorot_uniform',\n",
    "                 wq_kernel_initializer='glorot_uniform',\n",
    "                 **kwargs):\n",
    "        if isinstance(similarity,Callable):\n",
    "            self.similarity = similarity\n",
    "        elif isinstance(similarity,str) and similarity in (\"multiplicative\",\"dot_product\",\"additive\"):\n",
    "                self.similarity = similarity\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                    'similarity now only support \"multiplicative\",\"dot_product\",\"additive\",'\n",
    "                    'and you can input a function as the similarity function!'\n",
    "                                )\n",
    "        if (isinstance(\n",
    "            kernel_size,\n",
    "            Sequence) and len(kernel_size) == 2) or kernel_size is None:\n",
    "            self.kernel_size = kernel_size\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                    'kernel_size must be a Sequence with 2 int element')\n",
    "            \n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.wk_kernel_initializer = initializers.get(\n",
    "            wk_kernel_initializer)\n",
    "        self.wq_kernel_initializer = initializers.get(\n",
    "            wq_kernel_initializer)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape) != 3:\n",
    "            raise ValueError('A additive weight layer should be called '\n",
    "                             'by a (batch,time_step,dim)3D inputs.'\n",
    "                             'Got ' + str(input_shape) + ' inputs.')\n",
    "        time = input_shape[-2]\n",
    "        dim = input_shape[-1]\n",
    "        if self.similarity == \"additive\":\n",
    "            \n",
    "            if self.kernel_size is None:\n",
    "                self.kernel_size = (time,time)\n",
    "            r,d_a = self.kernel_size\n",
    "            self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(r,d_a),\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      trainable=True)\n",
    "                \n",
    "            self.wk_kernel = self.add_weight(\n",
    "                name='wk_kernel',\n",
    "                shape=(d_a, dim),\n",
    "                initializer=self.wk_kernel_initializer,\n",
    "            trainable=True)\n",
    "        elif self.similarity == \"multiplicative\":\n",
    "            self.kernel = self.add_weight(name='kernel',\n",
    "                                          shape=(\n",
    "                                              dim,dim),\n",
    "                                          initializer=self.kernel_initializer,\n",
    "                                          trainable=True)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # Be sure to call this somewhere!\n",
    "        super().build(input_shape)\n",
    "    def multiplicative(self, Source):\n",
    "        Source_t = K.permute_dimensions(Source, (0,2,1))\n",
    "        s = K.dot(Source,self.kernel)\n",
    "        print(s)\n",
    "        sim = K.batch_dot(s,Source_t)\n",
    "        print(sim)\n",
    "        return sim\n",
    "        \n",
    "    def dot_product(self, Source):\n",
    "        Source_t = K.permute_dimensions(Source, (0,2,1))\n",
    "        sim = K.batch_dot(Source,Source_t)\n",
    "        print(sim)\n",
    "        return sim\n",
    "        \n",
    "    def additive(self, Source):\n",
    "        Source_t = K.permute_dimensions(Source, (0,2,1))\n",
    "        f_att = K.dot(self.wk_kernel,Source_t)\n",
    "        f_att = K.permute_dimensions(f_att, (1,0,2))\n",
    "        sim = K.dot(self.kernel,K.tanh(f_att))\n",
    "        sim = K.permute_dimensions(sim, (1,0,2))\n",
    "        print(sim)\n",
    "        return sim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Source = inputs\n",
    "        if isinstance(self.similarity,Callable):\n",
    "            sim = self.similarity(Source)\n",
    "        else:\n",
    "            sim = getattr(self, self.similarity)(Source)\n",
    "        sm = activations.softmax(sim)\n",
    "        result = K.batch_dot(sm,Source)\n",
    "        print(result)\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"self_attention2d_layer_42/Reshape_2:0\", shape=(?, 20, 32), dtype=float32)\n",
      "Tensor(\"self_attention2d_layer_42/MatMul_1:0\", shape=(?, 20, 20), dtype=float32)\n",
      "Tensor(\"self_attention2d_layer_42/MatMul_2:0\", shape=(?, 20, 32), dtype=float32)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_43 (InputLayer)        (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "self_attention2d_layer_42 (S (None, 20, 32)            1024      \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 9,377\n",
      "Trainable params: 9,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huangsizhe/LIB/CONDA/anaconda/envs/python3.5/lib/python3.5/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))\n",
    "attention_mul =  SelfAttention2DLayer(similarity='multiplicative',kernel_size=(5,6))(inputs)#MyLayer((20,32))(inputs)#\n",
    "lstm_units = 32\n",
    "attention_mul = LSTM(lstm_units, return_sequences=False)(attention_mul)\n",
    "output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "m = Model(input=[inputs], output=output)\n",
    "\n",
    "m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = np.random.rand(20,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = np.random.rand(18,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wk = np.random.rand(12,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(k@wk).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wq = np.random.rand(20,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(wq@q.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (20,18) (18,18) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-350-bb7fc44863e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mwk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mwq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (20,18) (18,18) "
     ]
    }
   ],
   "source": [
    "(k@wk)+(q@wq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v =  np.random.rand(20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(v.T@k).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = np.random.rand(20,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vv = np.random.rand(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(k@vv).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.random.rand(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = np.random.rand(18,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = k@w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1121432 ,  0.35664993,  0.24638674,  0.18976187,  0.45051852,\n",
       "         0.28007788,  0.30429968,  0.10896963,  0.37784277,  0.15818082,\n",
       "         0.11349591,  0.15118776,  0.30723985,  0.40662203,  0.33915779,\n",
       "         0.04253393,  0.41135932,  0.47588102],\n",
       "       [ 0.48384752,  1.53861945,  1.05035995,  0.8302624 ,  1.94133307,\n",
       "         1.22395786,  1.31929431,  0.47444006,  1.63372104,  0.68215898,\n",
       "         0.49560182,  0.661576  ,  1.30174022,  1.740443  ,  1.45916821,\n",
       "         0.18600621,  1.77159176,  2.04782356],\n",
       "       [ 0.51202271,  1.62843195,  1.12817858,  0.86348186,  2.05759833,\n",
       "         1.2748229 ,  1.38774718,  0.49644283,  1.72426204,  0.72230243,\n",
       "         0.51669352,  0.68793441,  1.40886357,  1.86010041,  1.54957895,\n",
       "         0.1935674 ,  1.87900573,  2.1741455 ],\n",
       "       [ 0.11008194,  0.3500118 ,  0.23548987,  0.19205839,  0.44100711,\n",
       "         0.2827332 ,  0.30190753,  0.10911737,  0.37265406,  0.15511266,\n",
       "         0.11438   ,  0.15306079,  0.28961649,  0.39214744,  0.33084338,\n",
       "         0.04300256,  0.4021727 ,  0.4644292 ],\n",
       "       [ 0.40132991,  1.27617468,  0.86803481,  0.6915649 ,  1.60963228,\n",
       "         1.01912959,  1.09590016,  0.39460481,  1.35597893,  0.56573986,\n",
       "         0.41256832,  0.55107941,  1.07373267,  1.44011086,  1.20927208,\n",
       "         0.15491059,  1.46864146,  1.69722246],\n",
       "       [ 0.36743757,  1.16826324,  0.7840732 ,  0.64284149,  1.47163948,\n",
       "         0.94612154,  1.00870774,  0.36487919,  1.24440521,  0.51769419,\n",
       "         0.38269703,  0.51232496,  0.96301587,  1.306779  ,  1.1036676 ,\n",
       "         0.14392076,  1.34189441,  1.54936577],\n",
       "       [ 0.32404902,  1.03053383,  0.70872931,  0.55126983,  1.30119431,\n",
       "         0.81327095,  0.88092802,  0.31596949,  1.09270537,  0.45699784,\n",
       "         0.3294643 ,  0.43923166,  0.88172612,  1.17142445,  0.97897524,\n",
       "         0.12354027,  1.18783955,  1.37373409],\n",
       "       [ 0.10662397,  0.33918517,  0.24104205,  0.17426271,  0.42965635,\n",
       "         0.25798385,  0.2859145 ,  0.10131634,  0.35737667,  0.15056694,\n",
       "         0.10474713,  0.13879306,  0.30487215,  0.39406477,  0.32468137,\n",
       "         0.039109  ,  0.39284503,  0.45534054],\n",
       "       [ 0.21806486,  0.69338663,  0.46933742,  0.37786774,  0.87415555,\n",
       "         0.55658551,  0.59662678,  0.21519229,  0.737417  ,  0.30733954,\n",
       "         0.22525068,  0.30112261,  0.57906659,  0.77994832,  0.65630874,\n",
       "         0.08462595,  0.79740386,  0.92121243],\n",
       "       [ 0.23816116,  0.75747032,  0.52667702,  0.39989556,  0.95743768,\n",
       "         0.59061768,  0.64452948,  0.23026648,  0.80149054,  0.33601864,\n",
       "         0.23943896,  0.31858296,  0.65892364,  0.86731214,  0.72139464,\n",
       "         0.08965884,  0.87448648,  1.0120923 ],\n",
       "       [ 0.32962772,  1.04835389,  0.72699842,  0.55524854,  1.32476775,\n",
       "         0.81983649,  0.89304359,  0.31935982,  1.1098435 ,  0.46501846,\n",
       "         0.33230605,  0.44236068,  0.90831704,  1.19826181,  0.9978113 ,\n",
       "         0.12447562,  1.20983789,  1.39996108],\n",
       "       [ 0.34298777,  1.09082757,  0.75516548,  0.57893284,  1.37821057,\n",
       "         0.85465646,  0.92989211,  0.33274231,  1.15518443,  0.48383322,\n",
       "         0.34638039,  0.46123859,  0.94268939,  1.24540053,  1.03782902,\n",
       "         0.12977572,  1.25854197,  1.45615089],\n",
       "       [ 0.24227035,  0.77049888,  0.53263202,  0.40964037,  0.97335184,\n",
       "         0.60464615,  0.65722451,  0.23529726,  0.81618311,  0.3417372 ,\n",
       "         0.24503109,  0.32636779,  0.66440211,  0.87883329,  0.73281814,\n",
       "         0.09182082,  0.88877514,  1.02822435],\n",
       "       [ 0.32575654,  1.03611472,  0.72406672,  0.54363525,  1.31029292,\n",
       "         0.80333853,  0.87973752,  0.31371586,  1.09526324,  0.4596987 ,\n",
       "         0.32578856,  0.43307017,  0.90819294,  1.19035238,  0.98792448,\n",
       "         0.12191294,  1.19706054,  1.38590103],\n",
       "       [ 0.44992336,  1.43084348,  0.98454969,  0.76493404,  1.80673366,\n",
       "         1.12854264,  1.22285634,  0.43852979,  1.51701494,  0.63452824,\n",
       "         0.45719964,  0.60946798,  1.22520366,  1.62702682,  1.35942048,\n",
       "         0.17142644,  1.64937937,  1.90757132],\n",
       "       [ 0.10796838,  0.34341698,  0.24062172,  0.17960247,  0.43440528,\n",
       "         0.26547601,  0.29125859,  0.10376222,  0.36283691,  0.15237812,\n",
       "         0.10768149,  0.14307033,  0.30221002,  0.39523027,  0.32764497,\n",
       "         0.04028144,  0.39691523,  0.45961241],\n",
       "       [ 0.35702257,  1.13534753,  0.77714375,  0.61072705,  1.43288167,\n",
       "         0.90056174,  0.97242766,  0.34937122,  1.20491443,  0.50340615,\n",
       "         0.36471564,  0.48663006,  0.96448356,  1.28655264,  1.07738117,\n",
       "         0.13683805,  1.30776289,  1.51194565],\n",
       "       [ 0.13639526,  0.43383003,  0.30360114,  0.22722918,  0.54870718,\n",
       "         0.33583073,  0.36813156,  0.13120784,  0.45847089,  0.19248816,\n",
       "         0.13620709,  0.1810121 ,  0.38107594,  0.4988793 ,  0.41378821,\n",
       "         0.05096046,  0.50132324,  0.58046458],\n",
       "       [ 0.42552676,  1.35319128,  0.92605974,  0.72809234,  1.70777921,\n",
       "         1.0736027 ,  1.15911382,  0.41647467,  1.43616403,  0.59999285,\n",
       "         0.434789  ,  0.5801486 ,  1.14916994,  1.53319233,  1.28403995,\n",
       "         0.1631332 ,  1.55864073,  1.80196752],\n",
       "       [ 0.46312589,  1.47281991,  1.01265699,  0.78809171,  1.859599  ,\n",
       "         1.16261834,  1.25913351,  0.45166252,  1.56174617,  0.65312804,\n",
       "         0.47098102,  0.62792437,  1.25968292,  1.67390915,  1.39905535,\n",
       "         0.17661057,  1.69757874,  1.96321431]])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s@q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(k@w@q.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 20)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(k.T@w).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = k@w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.56967935,  1.13957991],\n",
       "       [ 6.80108574,  4.9554269 ],\n",
       "       [ 7.15955082,  5.19325489],\n",
       "       [ 1.55519432,  1.13803288],\n",
       "       [ 5.64839779,  4.12002862],\n",
       "       [ 5.19543016,  3.80455297],\n",
       "       [ 4.5430327 ,  3.30276969],\n",
       "       [ 1.47712727,  1.0628364 ],\n",
       "       [ 3.07430949,  2.24569032],\n",
       "       [ 3.32585045,  2.40973565],\n",
       "       [ 4.60755453,  3.34114439],\n",
       "       [ 4.79723194,  3.48051961],\n",
       "       [ 3.39030022,  2.46085421],\n",
       "       [ 4.5407952 ,  3.28482748],\n",
       "       [ 6.30656563,  4.58412114],\n",
       "       [ 1.50355706,  1.08677645],\n",
       "       [ 5.01366034,  3.65012031],\n",
       "       [ 1.90026988,  1.37405081],\n",
       "       [ 5.97611325,  4.35109981],\n",
       "       [ 6.49339227,  4.72102345]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s@k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(k@q.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3!=3!=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "t = K.ones((5,12, 3))\n",
    "t1 = t[:, :6,:] + 1\n",
    "t2 = t[:, 1:,:] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(5), Dimension(6), Dimension(3)])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
